{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d7a642-6d61-4625-ad29-2a71277a6ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/15 17:05:50 WARN Utils: Your hostname, a4ankan resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/03/15 17:05:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/15 17:05:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Created Successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ECommerceDWH</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7d27745927b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"ECommerceDWH\")\\\n",
    "    .config(\"spark.executor.memory\", \"4g\")\\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\")\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Print session info\n",
    "print(\"Spark Session Created Successfully!\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d887e9d-73d6-4cbd-be58-f6855da3b307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - vboxuser supergroup          0 2025-03-15 17:00 /retail_db\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22ee865d-8678-452e-98b6-1cedb72b0891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 44M\n",
      "-rw-rw-r-- 1 vboxuser vboxuser 16K Mar 15 17:04 analysis.ipynb\n",
      "-rw-r--r-- 1 vboxuser vboxuser 44M Sep 20  2019 data.csv\n",
      "-rw-rw-r-- 1 vboxuser vboxuser 12K Mar 15 16:01 LICENSE\n",
      "-rw-rw-r-- 1 vboxuser vboxuser  11 Mar 15 16:01 README.md\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /home/vboxuser/Desktop/retailDB/retail_db/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5746d0b3-6421-4c48-b4c1-85b050ef9fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: [PosixPath('/home/vboxuser/Desktop/retailDB/retail_db/.ipynb_checkpoints'), PosixPath('/home/vboxuser/Desktop/retailDB/retail_db/.git'), PosixPath('/home/vboxuser/Desktop/retailDB/retail_db/analysis.ipynb'), PosixPath('/home/vboxuser/Desktop/retailDB/retail_db/LICENSE'), PosixPath('/home/vboxuser/Desktop/retailDB/retail_db/README.md'), PosixPath('/home/vboxuser/Desktop/retailDB/retail_db/data.csv')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"/home/vboxuser/Desktop/retailDB/retail_db/\")\n",
    "print(\"Files in directory:\", list(data_path.glob(\"*\")))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9899b1eb-79ee-4f86-a41b-339fba32d6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"InvoiceNo\", StringType(), True),\n",
    "    StructField(\"StockCode\", StringType(), True),\n",
    "    StructField(\"Description\", StringType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True),\n",
    "    StructField(\"InvoiceDate\", StringType(), True),  # Will convert later\n",
    "    StructField(\"UnitPrice\", DoubleType(), True),\n",
    "    StructField(\"CustomerID\", IntegerType(), True),\n",
    "    StructField(\"Country\", StringType(), True)\n",
    "])\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(schema) \\\n",
    "    .load(f\"file://{data_path}/data.csv\")\n",
    "\n",
    "df.show(5)\n",
    "\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c674b7bc-dfca-44d7-8203-e51137ef6ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.cache()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1abbf57-6c43-4efb-9ecf-aaaeaedbe3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9875d7d3-fc63-4bc0-bab5-89f417d4e6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-03-15'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Get today's date in YYYY-MM-DD format\n",
    "today_date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "today_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3d662ac-ed96-4982-bd9c-8f759ef9df4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.write.format(\"parquet\").mode(\"overwrite\").save(f\"retail_db/{today_date}/raw.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "077799f0-ab64-466d-a5e6-5eca7911477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - vboxuser supergroup          0 2025-03-15 17:07 retail_db/2025-03-15/raw.parquet\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls retail_db/{today_date}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd4b9a-a8f7-4176-adc0-0c9d338e44df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
